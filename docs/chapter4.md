---
layout: default
title: "4ì¥: ë°ì´í„° ì²˜ë¦¬"
---

# 4ì¥: ë°ì´í„° ì²˜ë¦¬

## ê°œìš”

ì´ ì¥ì—ì„œëŠ” ëŒ€ê·œëª¨ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤. **ì„ ì–¸í˜• í”„ë¡œê·¸ë˜ë°**, **ë…¼ë¦¬ í”„ë¡œê·¸ë˜ë°**, **SQL**, ê·¸ë¦¬ê³  **ë¶„ì‚° ì»´í“¨íŒ…** ê¸°ì´ˆë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.

---

## ğŸ“Œ 4.1ì¥: ì„ ì–¸í˜• í”„ë¡œê·¸ë˜ë° (Declarative Programming)

### ëª…ë ¹í˜• vs ì„ ì–¸í˜•

**ëª…ë ¹í˜• (Imperative)**: ì–´ë–»ê²Œ í•˜ëŠ”ê°€ë¥¼ ëª…ì‹œ

```python
# ëª…ë ¹í˜•: ë‹¨ê³„ë³„ ì§€ì‹œ
total = 0
for x in numbers:
    if x > 5:
        total += x * 2
print(total)
```

**ì„ ì–¸í˜• (Declarative)**: ë¬´ì—‡ì„ ì›í•˜ëŠ”ê°€ë¥¼ ëª…ì‹œ

```python
# ì„ ì–¸í˜•: ê²°ê³¼ ì •ì˜
total = sum(x * 2 for x in numbers if x > 5)
```

### í•¨ìˆ˜í˜• ìŠ¤íƒ€ì¼

```python
# íŒŒì´í”„ë¼ì¸ êµ¬ì„±
def pipeline(data, *functions):
    result = data
    for f in functions:
        result = f(result)
    return result

# ê° ë‹¨ê³„ ì •ì˜
filter_large = lambda nums: [x for x in nums if x > 5]
double = lambda nums: [x * 2 for x in nums]
sum_all = lambda nums: sum(nums)

# ì‚¬ìš©
result = pipeline(numbers, filter_large, double, sum_all)
```

---

## ğŸ“Œ 4.2ì¥: ë…¼ë¦¬ í”„ë¡œê·¸ë˜ë° (Logic Programming)

### ë…¼ë¦¬ í”„ë¡œê·¸ë˜ë° ê°œë…

ë…¼ë¦¬ í”„ë¡œê·¸ë˜ë°ì€ **ì‚¬ì‹¤(Facts)**ê³¼ **ê·œì¹™(Rules)**ë¡œ í”„ë¡œê·¸ë¨ì„ ì‘ì„±í•©ë‹ˆë‹¤.

```
# ì‚¬ì‹¤ (Facts)
parent(tom, bob)
parent(bob, alice)

# ê·œì¹™ (Rules)
grandparent(X, Z) :- parent(X, Y), parent(Y, Z)

# ì¿¼ë¦¬ (Query)
?- grandparent(tom, alice)
```

### Pythonì—ì„œì˜ ê°„ë‹¨í•œ êµ¬í˜„

```python
# ë°ì´í„°ë² ì´ìŠ¤
facts = [
    ("parent", ("tom", "bob")),
    ("parent", ("bob", "alice")),
]

# ê·œì¹™
rules = {
    "grandparent": lambda x, z: any(
        ("parent", (x, y)) in facts and
        ("parent", (y, z)) in facts
        for y in range(100)
    )
}

# ì¿¼ë¦¬
def query(relation, args):
    if relation == "parent":
        return ("parent", args) in facts
    elif relation == "grandparent":
        return rules["grandparent"](*args)

# ì‚¬ìš©
print(query("parent", ("tom", "bob")))        # True
print(query("grandparent", ("tom", "alice"))) # True
```

---

## ğŸ“Œ 4.3ì¥: SQLì„ í†µí•œ ë°ì´í„° ì¡°íšŒ

### SQL ê¸°ì´ˆ

**SELECT**: ë°ì´í„° ì¡°íšŒ

```sql
-- ëª¨ë“  í•™ìƒì˜ ì´ë¦„ê³¼ í•™ë²ˆ
SELECT name, student_id FROM students;

-- ì¡°ê±´ë¶€ ì¡°íšŒ
SELECT name, grade FROM students WHERE grade >= 80;

-- ì •ë ¬
SELECT name, grade FROM students ORDER BY grade DESC;
```

### Pythonì—ì„œ SQL ì‚¬ìš©

```python
import sqlite3

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
conn = sqlite3.connect(':memory:')
cursor = conn.cursor()

# í…Œì´ë¸” ìƒì„±
cursor.execute('''
    CREATE TABLE students (
        id INTEGER PRIMARY KEY,
        name TEXT,
        grade INTEGER
    )
''')

# ë°ì´í„° ì‚½ì…
cursor.execute("INSERT INTO students VALUES (1, 'ì² ìˆ˜', 85)")
cursor.execute("INSERT INTO students VALUES (2, 'ì˜í¬', 92)")

# ë°ì´í„° ì¡°íšŒ
cursor.execute("SELECT * FROM students WHERE grade >= 90")
for row in cursor.fetchall():
    print(row)

conn.close()
```

### JOIN ì—°ì‚°

```sql
-- ë‚´ë¶€ ì¡°ì¸
SELECT students.name, courses.title
FROM students
INNER JOIN enrollments ON students.id = enrollments.student_id
INNER JOIN courses ON enrollments.course_id = courses.id;

-- ì™¼ìª½ ì™¸ë¶€ ì¡°ì¸
SELECT students.name, courses.title
FROM students
LEFT JOIN enrollments ON students.id = enrollments.student_id
LEFT JOIN courses ON enrollments.course_id = courses.id;
```

### ì§‘ê³„ í•¨ìˆ˜

```sql
-- í•™ìƒ ìˆ˜
SELECT COUNT(*) FROM students;

-- í‰ê·  ì„±ì 
SELECT AVG(grade) FROM students;

-- ê·¸ë£¹ë³„ ì§‘ê³„
SELECT course_id, COUNT(*) as count
FROM enrollments
GROUP BY course_id
HAVING COUNT(*) > 5;
```

---

## ğŸ“Œ 4.4ì¥: ë°ì´í„° í”„ë ˆì„ (DataFrames)

### Pandas ì†Œê°œ

```python
import pandas as pd

# ë°ì´í„°í”„ë ˆì„ ìƒì„±
df = pd.DataFrame({
    'name': ['ì² ìˆ˜', 'ì˜í¬', 'ë¯¼ì¤€'],
    'age': [30, 28, 35],
    'city': ['ì„œìš¸', 'ë¶€ì‚°', 'ì„œìš¸']
})

# ë°ì´í„° ì¡°íšŒ
print(df.head())              # ì²˜ìŒ 5í–‰
print(df[df['age'] > 30])     # 30ì‚´ ì´ìƒ

# í†µê³„
print(df['age'].mean())       # í‰ê·  ë‚˜ì´
print(df.groupby('city').size())  # ë„ì‹œë³„ ì¸êµ¬
```

### ë°ì´í„° ë³€í™˜

```python
# í•„í„°ë§
young = df[df['age'] < 30]

# ì •ë ¬
sorted_df = df.sort_values('age', ascending=False)

# ìƒˆ ì—´ ì¶”ê°€
df['age_group'] = df['age'].apply(
    lambda x: 'ì ŠìŒ' if x < 30 else 'ì„±ì¸'
)

# í–‰ ê²°í•© (UNION)
combined = pd.concat([df1, df2])

# ì—´ í•©ì¹˜ê¸° (JOIN)
merged = pd.merge(df1, df2, on='id')
```

---

## ğŸ“Œ 4.5ì¥: ë¶„ì‚° ì»´í“¨íŒ… ê¸°ì´ˆ

### Map-Reduce íŒ¨í„´

**Map**: ë°ì´í„°ë¥¼ ë³€í™˜

```python
# ê° ë‹¨ì–´ì˜ ê¸¸ì´ë¥¼ ë§¤í•‘
words = ['hello', 'world', 'python']
word_lengths = list(map(len, words))
# [5, 5, 6]
```

**Reduce**: ë°ì´í„°ë¥¼ ì¶•ì•½

```python
from functools import reduce

# ëª¨ë“  ê¸¸ì´ì˜ í•©
total_length = reduce(lambda a, b: a + b, word_lengths)
# 16
```

### Word Count ì˜ˆì œ

```python
from functools import reduce
from collections import defaultdict

text = """
python is great
python is powerful
python is elegant
"""

# Map: ê° ë‹¨ì–´ë¥¼ (word, 1)ë¡œ ë³€í™˜
words_with_count = [
    (word.strip(), 1)
    for word in text.lower().split()
    if word.strip()
]

# Shuffle: ê°™ì€ ë‹¨ì–´ë¼ë¦¬ ê·¸ë£¹í™”
word_groups = defaultdict(list)
for word, count in words_with_count:
    word_groups[word].append(count)

# Reduce: ê° ê·¸ë£¹ì˜ ê°œìˆ˜ í•©ì‚°
word_counts = {
    word: sum(counts)
    for word, counts in word_groups.items()
}

print(word_counts)
# {'python': 3, 'is': 3, 'great': 1, 'powerful': 1, 'elegant': 1}
```

### ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬

```python
# ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
def process_stream(data_stream):
    """ìŠ¤íŠ¸ë¦¼ ë°ì´í„° ì²˜ë¦¬"""
    accumulator = 0
    for data in data_stream:
        accumulator += data
        yield {
            'value': data,
            'cumulative': accumulator
        }

# ì‚¬ìš©
stream = range(1, 6)
results = list(process_stream(stream))
for result in results:
    print(result)
```

---

## ğŸ“Œ 4.6ì¥: ë³‘ë ¬ ì²˜ë¦¬

### ë©€í‹°í”„ë¡œì„¸ì‹±

```python
from multiprocessing import Pool

def square(x):
    return x * x

# ë³‘ë ¬ ì²˜ë¦¬
with Pool(4) as p:
    results = p.map(square, range(10))

print(results)  # [0, 1, 4, 9, 16, ...]
```

### ë©€í‹°ìŠ¤ë ˆë”©

```python
import threading
import time

def worker(name):
    for i in range(3):
        print(f"{name}ì´ ì‘ì—… ì¤‘... {i}")
        time.sleep(1)

threads = []
for i in range(3):
    t = threading.Thread(target=worker, args=(f"ìŠ¤ë ˆë“œ {i}",))
    threads.append(t)
    t.start()

for t in threads:
    t.join()  # ëª¨ë“  ìŠ¤ë ˆë“œ ëŒ€ê¸°
```

---

## ğŸ“Œ 4.7ì¥: ìµœì í™” (Optimization)

### ì‹œê°„ ë³µì¡ë„ ë¶„ì„

```python
# O(n) - ì„ í˜•
def find_max(numbers):
    return max(numbers)

# O(nÂ²) - ì´ì°¨
def bubble_sort(numbers):
    n = len(numbers)
    for i in range(n):
        for j in range(n - i - 1):
            if numbers[j] > numbers[j + 1]:
                numbers[j], numbers[j + 1] = numbers[j + 1], numbers[j]

# O(log n) - ë¡œê·¸
def binary_search(sorted_list, target):
    left, right = 0, len(sorted_list) - 1
    while left <= right:
        mid = (left + right) // 2
        if sorted_list[mid] == target:
            return mid
        elif sorted_list[mid] < target:
            left = mid + 1
        else:
            right = mid - 1
    return -1
```

### ìºì‹± (Memoization)

```python
from functools import lru_cache

# ìµœì í™” ì „ (ëŠë¦¼)
def fib_slow(n):
    if n <= 1:
        return n
    return fib_slow(n - 1) + fib_slow(n - 2)

# ìµœì í™” í›„ (ë¹ ë¦„)
@lru_cache(maxsize=None)
def fib_fast(n):
    if n <= 1:
        return n
    return fib_fast(n - 1) + fib_fast(n - 2)

# ì„±ëŠ¥ ë¹„êµ
import time

start = time.time()
result = fib_slow(35)
print(f"ëŠë¦° ë²„ì „: {time.time() - start:.2f}ì´ˆ")

start = time.time()
result = fib_fast(35)
print(f"ë¹ ë¥¸ ë²„ì „: {time.time() - start:.4f}ì´ˆ")
```

---

## ğŸ“Œ 4.8ì¥: ì‚¬ë¡€ ì—°êµ¬

### ì¶”ì²œ ì‹œìŠ¤í…œ

```python
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity

# ì‚¬ìš©ì-ì˜í™” í‰ì  í–‰ë ¬
ratings = pd.DataFrame({
    'ìœ ì €1': [5, 3, 0, 1],
    'ìœ ì €2': [4, 0, 0, 1],
    'ìœ ì €3': [1, 1, 0, 5],
    'ìœ ì €4': [1, 0, 0, 4]
}, index=['ì˜í™”A', 'ì˜í™”B', 'ì˜í™”C', 'ì˜í™”D'])

# ìœ ì‚¬ë„ ê³„ì‚°
similarity = cosine_similarity(ratings.T)

# ìœ ì €1ê³¼ ìœ ì‚¬í•œ ìœ ì € ì°¾ê¸°
similar_users = pd.Series(similarity[0]).nlargest(2).index
print(f"ìœ ì €1ê³¼ ìœ ì‚¬í•œ ìœ ì €: {similar_users}")
```

### ë°ì´í„° ì‹œê°í™”

```python
import matplotlib.pyplot as plt

# ë°ì´í„° ì¤€ë¹„
categories = ['A', 'B', 'C', 'D']
values = [23, 45, 56, 78]

# ë§‰ëŒ€ ê·¸ë˜í”„
plt.bar(categories, values)
plt.title('ì¹´í…Œê³ ë¦¬ë³„ ê°’')
plt.xlabel('ì¹´í…Œê³ ë¦¬')
plt.ylabel('ê°’')
plt.show()

# ì„  ê·¸ë˜í”„
time_series = [1, 4, 9, 16, 25]
plt.plot(time_series)
plt.title('ì‹œê°„ ê²½ê³¼ì— ë”°ë¥¸ ë³€í™”')
plt.show()
```

---

## ğŸ¯ í•µì‹¬ ìš”ì•½

| ì£¼ì œ | ì„¤ëª… | ê¸°ìˆ  |
|------|------|------|
| ì„ ì–¸í˜• í”„ë¡œê·¸ë˜ë° | ë¬´ì—‡ì„ ì›í•˜ëŠ”ê°€ í‘œí˜„ | í•¨ìˆ˜í˜• íŒŒì´í”„ë¼ì¸ |
| ë…¼ë¦¬ í”„ë¡œê·¸ë˜ë° | ì‚¬ì‹¤ê³¼ ê·œì¹™ìœ¼ë¡œ í‘œí˜„ | Prolog, ë…¼ë¦¬ ê·œì¹™ |
| SQL | ë°ì´í„° ì¡°íšŒ ì–¸ì–´ | SELECT, JOIN, GROUP BY |
| ë°ì´í„°í”„ë ˆì„ | í…Œì´ë¸” í˜•íƒœ ë°ì´í„° | Pandas |
| Map-Reduce | ë¶„ì‚° ë°ì´í„° ì²˜ë¦¬ | ë³‘ë ¬ ê³„ì‚° |
| ìµœì í™” | ì„±ëŠ¥ ê°œì„  | ì‹œê°„ ë³µì¡ë„, ìºì‹± |

---

## ğŸ“š ê´€ë ¨ í˜ì´ì§€

- [3ì¥: ì»´í“¨í„° í”„ë¡œê·¸ë¨ í•´ì„](./chapter3.md)
- [ë©”ì¸ í˜ì´ì§€](./index.md)

---

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

ì´ êµê³¼ì„œë¥¼ ì™„ë£Œí•˜ë©´:
- Pythonì„ ëŠ¥ìˆ™í•˜ê²Œ ë‹¤ë£° ìˆ˜ ìˆìŠµë‹ˆë‹¤
- í”„ë¡œê·¸ë˜ë°ì˜ ë³¸ì§ˆì ì¸ ê°œë…ì„ ì´í•´í•©ë‹ˆë‹¤
- ë³µì¡í•œ ë¬¸ì œë¥¼ ì²´ê³„ì ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

**UC Berkeley CS61A ê³¼ì •ì— ë„ì „í•´ë³´ì„¸ìš”!**

---

**ì´ í˜ì´ì§€ëŠ” í˜„ì¬ ì œì‘ ì¤‘ì´ë©°, ë” ìì„¸í•œ ì½”ë“œ ì˜ˆì‹œì™€ ì—°ìŠµ ë¬¸ì œê°€ ì¶”ê°€ë  ì˜ˆì •ì…ë‹ˆë‹¤.**
